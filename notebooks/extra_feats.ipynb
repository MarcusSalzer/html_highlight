{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features\n",
    "\n",
    "LSTM tagger that includes extra features, generated from the input text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from datatools import plotting\n",
    "\n",
    "from src import torch_util, util\n",
    "\n",
    "plotting.set_plotly_template()\n",
    "\n",
    "data = util.load_examples_json(split_idx_id=\"0301\")\n",
    "display(data[\"train\"].head(5))\n",
    "vocab, token2idx, tag_vocab, tag2idx = util.make_vocab(data[\"train\"])\n",
    "print(f\"vocab: {len(vocab)} tokens | tag_vocab: {len(tag_vocab)} tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(torch_util)\n",
    "print(torch_util.make_extra_feats([\"Sys\", \"print\", \"\\n\", \"9\", \"\\n\", \"==\"]))\n",
    "print(torch_util.make_extra_feats([\"print\", \"(\", \")\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(torch_util)\n",
    "NF = 3\n",
    "BS = 4\n",
    "\n",
    "constr_params = {\n",
    "    \"embedding_dim\": 16,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"n_lstm_layers\": 2,\n",
    "    \"dropout_lstm\": 0.3,\n",
    "    \"bidi\": True,\n",
    "    \"token_vocab_size\": len(vocab),\n",
    "    \"label_vocab_size\": len(tag_vocab),\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\nModels:\")\n",
    "model_base = torch_util.LSTMTagger(**constr_params)\n",
    "model_feats = torch_util.LSTMTagger(**constr_params, n_extra=NF)\n",
    "\n",
    "dls_base = {\n",
    "    k: torch_util.data2torch(d, BS, token2idx, tag2idx) for k, d in data.items()\n",
    "}\n",
    "\n",
    "print(\"data shape (base):\")\n",
    "ex = next(iter(dls_base[\"train\"]))\n",
    "for k, t in ex[0].items():\n",
    "    print(f\"  - {k}\", t.shape)\n",
    "print(\"  -> out\", model_base(**ex[0]).shape)\n",
    "\n",
    "dls_feats = {\n",
    "    k: torch_util.data2torch(d, BS, token2idx, tag2idx, extra_feats=NF)\n",
    "    for k, d in data.items()\n",
    "}\n",
    "print(\"\\ndata shape (w. feats):\")\n",
    "ex = next(iter(dls_feats[\"train\"]))\n",
    "for k, t in ex[0].items():\n",
    "    print(f\"  - {k}\", t.shape)\n",
    "print(\"  -> out\", model_feats(**ex[0]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epoch = 5  # ca 40+ to converge\n",
    "# lrs = torch.optim.lr_scheduler.CosineAnnealingLR()\n",
    "print(\"BASE MODEL\")\n",
    "losses_base = torch_util.train_loop(\n",
    "    model_base,\n",
    "    dls_base[\"train\"],\n",
    "    dls_base[\"val\"],\n",
    "    epochs=N_epoch,\n",
    "    reduce_lr_on_plat={\"factor\": 0.75, \"patience\": 5},\n",
    ")\n",
    "print(\"FEATS MODEL\")\n",
    "losses_feats = torch_util.train_loop(\n",
    "    model_feats,\n",
    "    dls_feats[\"train\"],\n",
    "    dls_feats[\"val\"],\n",
    "    epochs=N_epoch,\n",
    "    reduce_lr_on_plat={\"factor\": 0.75, \"patience\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in losses_base.keys():\n",
    "    go.Figure(\n",
    "        [\n",
    "            go.Scatter(y=losses_base[k], name=\"base\"),\n",
    "            go.Scatter(y=losses_feats[k], name=\"feats\"),\n",
    "        ],\n",
    "    ).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_my_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
