{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json as jorre\n",
      "\n",
      "x = 37\n",
      "for k in range(x):\n",
      "    print(\"öh\" * k)\n",
      "    \n",
      "this_variable = \"hej på dig\"\n",
      "\n",
      "a_longer123string = this_variable + \"ööhö\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_file = \"input.py\"\n",
    "\n",
    "with open(input_file) as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['import', ' ', 'json', ' ', 'as', ' ', 'jorre', '\\n\\n', 'x', ' ', '=', ' ', '37', '\\n', 'for', ' ', 'k', ' ', 'in', ' ', 'range', '(', 'x', ')', ':', '\\n', ' ', ' ', ' ', ' ', 'print', '(', '\"öh\"', ' ', '*', ' ', 'k', ')', '\\n', ' ', ' ', ' ', ' ', '\\n', 'this_variable', ' ', '=', ' ', '\"hej på dig\"', '\\n\\n', 'a_longer123string', ' ', '=', ' ', 'this_variable', ' ', '+', ' ', '\"ööhö\"', '\\n']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text) -> list[str]:\n",
    "    \"\"\"Tokenize a text\"\"\"\n",
    "    # Possible string delimiters\n",
    "    string_delims = {'\"', \"'\", '\"\"\"', \"'''\"}\n",
    "\n",
    "    # split everything\n",
    "    tokens = re.findall(r\"(\\w+|[^\\w\\s]+|\\s+|\\n)\", text)\n",
    "\n",
    "    ## split tokens without letters or numbers or repeated operators\n",
    "    tmp = []\n",
    "    for t in tokens:\n",
    "        if bool(re.search(r\"\\p{L}|\\p{digit}\", t)):\n",
    "            tmp.append(t)\n",
    "        elif len(t) > 1 and all((c == t[0] for c in t)):\n",
    "            tmp.append(t)\n",
    "        else:\n",
    "            tmp.extend(list(t))\n",
    "\n",
    "    tokens = tmp\n",
    "\n",
    "    ## reunite string literals\n",
    "    tmp = []\n",
    "    tags = []\n",
    "    current_delim = \"\"\n",
    "    current_string = \"\"\n",
    "    for t in tokens:\n",
    "        if current_delim == \"\":\n",
    "            if t in string_delims:\n",
    "                # start a string\n",
    "                current_delim = t\n",
    "                current_string += t\n",
    "            else:\n",
    "                tmp.append(t)\n",
    "                tags.append(\"<unk>\")\n",
    "        else:\n",
    "            if t == current_delim:\n",
    "                # break current string\n",
    "                current_delim = \"\"\n",
    "                current_string += t\n",
    "                tmp.append(current_string)\n",
    "                tags.append(\"str\")\n",
    "                current_string = \"\"\n",
    "            else:\n",
    "                # add to current string\n",
    "                current_string += t\n",
    "\n",
    "    tokens = tmp\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "tokens, tags = tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens 60\n",
      "10 op '='\n",
      "12 num '37'\n",
      "21 brac_op '('\n",
      "23 brac_cl ')'\n",
      "24 op ':'\n",
      "31 brac_op '('\n",
      "32 str '\"öh\"'\n",
      "34 op '*'\n",
      "37 brac_cl ')'\n",
      "46 op '='\n",
      "52 op '='\n",
      "56 op '+'\n",
      "58 str '\"ööhö\"'\n"
     ]
    }
   ],
   "source": [
    "print(\"# tokens\", len(tokens))\n",
    "\n",
    "known_chars = {\n",
    "    \"op\": r\"=!%&/+-*:\",\n",
    "    \"brac_op\": r\"([{\",\n",
    "    \"brac_cl\": r\")]}\",\n",
    "}\n",
    "\n",
    "# first: tag individual tokens\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    if token.isdigit():\n",
    "        tags[i] = \"num\"\n",
    "        continue\n",
    "    elif bool(re.search(\"\\s\", token)):\n",
    "        tags[i] = \"wsp\"\n",
    "\n",
    "    for key in known_chars.keys():\n",
    "        if token in known_chars[key]:\n",
    "            tags[i] = key\n",
    "            break\n",
    "\n",
    "\n",
    "# print\n",
    "for i, x in enumerate(zip(tags, tokens)):\n",
    "    if x[0] != \"<unk>\" and x[0] != \"wsp\":\n",
    "        print(i, x[0], repr(x[1]))\n",
    "\n",
    "# second: tag based on context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\timport\n",
      "<unk>\tjson\n",
      "<unk>\tas\n",
      "<unk>\tjorre\n",
      "<unk>\tx\n",
      "<unk>\tfor\n",
      "<unk>\tk\n",
      "<unk>\tin\n",
      "<unk>\trange\n",
      "<unk>\tx\n",
      "<unk>\tprint\n",
      "<unk>\tk\n",
      "<unk>\tthis_variable\n",
      "<unk>\ta_longer123string\n",
      "<unk>\tthis_variable\n"
     ]
    }
   ],
   "source": [
    "for x in zip(tags, tokens):\n",
    "    if x[0] == \"<unk>\":\n",
    "        print(\"\\t\".join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"var\", \"op\", \"num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json as jorre<br>\n",
      "<br>\n",
      "x = 37<br>\n",
      "for k in range(x):<br>\n",
      "&nbsp; &nbsp; print(\"öh\" * k)<br>\n",
      "&nbsp; &nbsp; <br>\n",
      "this_variable = \"hej på dig\"<br>\n",
      "<br>\n",
      "a_longer123string = this_variable + \"ööhö\"<br>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\".join(tokens)\n",
    "\n",
    "text = re.sub(r\"  \", r\"&nbsp; \", text)\n",
    "text = re.sub(r\"\\n\", r\"<br>\\n\", text)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
